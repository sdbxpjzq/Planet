## 隔离性(Isolation) 也叫 多版本并发控制

一个事务所做的修改在最终提交以前，对其他事务是不可见的

InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制、数据的隐藏列、undo log和类next-key lock机制



## MVCC

InnoDB的 MVCC ，是通过在每行记录的后面保存`两个隐藏的列`来实现的。



那不同的SQL请求，MySQL 是如何实现得？

- select 请求根据系统当前的事务版本号去和数据列中版本号做对比，先过滤存在过期时间的数据列。然后取出满足小于或者等于当前版本号的记录。
- insert  innodb为每插入一行，就保留当前系统版本号为行版本
- delete  innodb为删除每一行，就保存当前系统版本号作为行删除标识。
- update  innodb为insert 插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。



![](https://youpaiyun.zongqilive.cn/image/20200714162810.png)



那这个机制有什么好处？

它主要实现思想是通过数据多版本来做到**「读写分离」**。每个请求给到不同版数据来执行。从而实现不加锁读进而做到读写并行。
**「MVCC机制实现还需要依赖于 undo log与read view」**

undo log: undo log 中记录某行记录的多个版本的数据。

read view: 用来判断当前版本数据的可读性



那这 MVCC 是如何保证多个版本数据得最终一致呢？

因数据操作为多个版本，所以它支持读写并行。

在请求进行事务操作前，会先入到读、写队列里面，然后再分别执行读写请求。若第一个写请求执行事务但未提交，但这时它就会拿到最新版本。

如果此时读请求进入也会直接执行，只不过读取数据时得系统版本就为未执行写请求的版本号，根据它来进行数据的读取。

这样在事务未进行提交前，所有读操作读取到的数据是一样的，因为它受系统当前版本控制。读取的都是同一个版本数据。



MySQL是多线程， 那同时有多个线程修改同一行数据，这种情况怎么处理的？

一般如果系统达到并发执行的情况，对用户请求得要求是很高的，每秒至少得几万请求，如有并发问题产生。

假如事务 A、B 都要执行 update 操作，事务A先 update 数据时，会先获取行锁，锁定数据，当事务 B 要进行 update 操作时，也会尝试获取该数据行的行锁，但此时已经被事务A占有，故事务B只能 wait。

如事务A，是个很费时的大SQL，长时间没释放锁。那么事务 B 就会等待超时。

查询全局等待事务锁超时时间
SHOW GLOBAL VARIABLES LIKE 'innodb_lock_wait_timeout';



**「 \**面试官：\**」** 这个是在 update 的where后的条件是在有索引的情况下吧？

**「 \**吒吒辉：\**」** 嗯，是的，因为 innodb 的行数只有索引才会触发，锁定的是行锁

**「 \**面试官：\**」** 那没有索引的条件下，就没办法快速定位到数据行呀？

**「 \**吒吒辉：\**」** 若是没有索引的条件下，就会退化为表锁。然后获取所有行后，Mysql 再过滤符合条件的的行并释放锁。往后只有符合条件的行才持有锁。

**「 \**吒吒辉：\**」** 这样就降低了并发度，并且性能开销也会很大。



而最后的一致性，实际上是通过原子性、持久性、隔离性来实现的



### MySQL 内核工作原理

**「 \**面试官：\**」** 那请继续数据是如何刷盘？这样得工作模式是怎么避免频繁读写得?

**「 \**吒吒辉：\**」** 说到数据刷盘，首先得谈下 innodb 缓冲池。

buffer pool 主要由数据、索引、插入缓冲、自适应哈希索引、锁等组成。

不同请求会根据 buffer pool里面对应部分数据来执行相关的操作。buffer pool中的数据会根据配置参数定期同步到磁盘中；只是这里刷盘的数据主要由 **「数据和日志」** 组成。

#### 数据

\* **由 innodb_max_dirty_pages_pct 参数决定。在说到这个之前，得说说\**「脏页」\**。**

> ❝
>
> 脏页指存在于内存中的数据，但未同步到持久化存储里面，因为数据库的数据用页来读取，故此称之为脏页。
>
> ❞

innodb_max_dirty_pages_pct 参数可动态调整，最小值为0， 最大值为99.99，默认值为 75。

根据缓冲池的大小和存储脏页的数量计算比例，如果满足了就调用后台线程把数据刷新到持久层当中里面。

这样做的好处就是合并其它数据页，从而提高写入的效率。



#### 日志

由 innodb_flush_log_at_trx_commit 变量来控制日志缓冲刷新频繁程度。

- 0：把日志缓冲写到日志文件，并且每秒钟刷新一次持久化存储，但是事务提交时不做任何事。
- 1：将日志缓冲写到日志文件，并且每次事务提交都刷新到持久化存储。这是默认的(并且是最安全的)设置，该设置能保证不会丢失任何已经提交的事务，**「除非磁盘或者操作系统是“伪”刷新，即写入到磁盘缓冲」**。
- 2：每次提交时把日志缓冲写到日志文件，但是并不刷新到持久化存储。InnoDB 每秒做一次刷新到持久化存储。一般也会选2，如果MySQL进程“挂了”，2 不会丢失任何事务。如果整个服务器“挂了”或者断电了，则还是可能会丢失 1s 的事务。

**「\**为什么上面把日志缓冲写到日志文件，还没到持久化存储呢？\**」**

因为在大部分操作系统中，把日志缓冲写到日志文件只是简单地把数据从 InnoDB  的内存缓冲转移到了操作系统的缓存，也是在内存里，并没有真的把数据写到了持久化存储。所以还需要进行数据磁盘同步的刷写。

**「 \**吒吒辉：\**」** 缓冲池是降低频繁得读写请求，这个得分情况来看：

- 读请求：请求首先在缓冲池下面找缓存的数据，从而避免每次访问都进行磁盘IO。
- 写请求：事务请求执行时，先根据日志缓冲配置的方式把数据记录到日志文件中，等数据的脏页达到一定比例或内存不够时，就会把数据落地磁盘上。
  从而把大量磁盘的随机I/O改写为顺序I/O。
  每次更新相关请求都基于 MVCC 特性拿到当前操作数据最新版本，从而并发执行多个版本。

















